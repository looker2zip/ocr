{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "03d9819f",
   "metadata": {},
   "source": [
    "# 1. 라브러리 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "567e8760",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import urllib.request\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a70f495f",
   "metadata": {},
   "source": [
    "# 2. 데이터 준비\n",
    "'''\n",
    "https://raw.githubusercontent.com/Franck-Dernoncourt/NeuroNER/master/neuroner/data/conll2003/en/train.txt\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "29ca409f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tagged_sentences =[]\n",
    "sentence = []\n",
    "\n",
    "with urllib.request.urlopen('https://raw.githubusercontent.com/Franck-Dernoncourt/NeuroNER/master/neuroner/data/conll2003/en/train.txt') as f:\n",
    "    for line in f:\n",
    "        line = line.decode('utf-8')\n",
    "        if len(line) == 0 or line.startswith('-DOCSTART') or line[0] == \"\\n\":\n",
    "            if len(sentence) > 0:\n",
    "                tagged_sentences.append(sentence)\n",
    "                sentence =[]\n",
    "            continue\n",
    "        splits = line.strip().split(' ')\n",
    "        word = splits[0].lower()\n",
    "        sentence.append([word, splits[-1]])\n",
    "\n",
    "print(len(tagged_sentences))\n",
    "print(tagged_sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7886982a",
   "metadata": {},
   "source": [
    "# 3.데이터 전처리\n",
    "## 3-1. 단어와 개체명 태그를 분리해서 데이터를 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9794318e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences, ner_tags =[],[]\n",
    "\n",
    "for tagged_sentence in tagged_sentences:\n",
    "    sentence, tag_info =zip(*tagged_sentence)\n",
    "    sentences.append(list(sentence))\n",
    "    ner_tags.append(list(tag_info))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2408d801",
   "metadata": {},
   "source": [
    "## 3-2. 정제 및 빈도 수가 높은 상위 단어들만 추출하기 위해 토큰화 작업"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "101136f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 4000\n",
    "src_tokenizer = Tokenizer(num_words=max_words, oov_token='OOV')\n",
    "src_tokenizer.fit_on_texts(sentences)\n",
    "\n",
    "tar_tokenizer = Tokenizer()\n",
    "tar_tokenizer.fit_on_texts(ner_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "672bdc06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4000\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "vocab_size = max_words\n",
    "tag_size = len(tar_tokenizer.word_index) + 1\n",
    "\n",
    "print(vocab_size)\n",
    "print(tag_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc574a0",
   "metadata": {},
   "source": [
    "## 3-3.데이터를 학습에 활용하기 위해 데이터를 배열로 변환\n",
    "## 해당 작업은 토콘화 툴의 texts_to_sequences()를 통해 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "721a8bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = src_tokenizer.texts_to_sequences(sentences)\n",
    "y_train = tar_tokenizer.texts_to_sequences(ner_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468d8c83",
   "metadata": {},
   "source": [
    "## 학습에 투입할 대는 동일한 길이를 갖고 있어야 하므로, 지정해 둔 최대 길이에 맞춰 모든 데이터를 동일한 길이로 맞춰준다.\n",
    "## 일반적으로 길이를 맞출 때는 모자란 길이만큼 0을 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "591ef972",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = 70\n",
    "X_train = pad_sequences(X_train, padding='post', maxlen=max_len)\n",
    "y_train = pad_sequences(y_train, padding='post', maxlen=max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5468a3f5",
   "metadata": {},
   "source": [
    "## 훈련, 실험 데이터 분리 및 원 핫 인코딩을 시행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84877857",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=.2, random_state=111)\n",
    "\n",
    "y_train = to_categorical(y_train, num_classes=tag_size)\n",
    "y_test = to_categorical(y_test, num_classes=tag_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7246acb0",
   "metadata": {},
   "source": [
    "## 최종적으로 생성된 데이터셋의 크기는 다음과 같음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "838b4bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11232, 70)\n",
      "(11232, 70, 10)\n",
      "(2809, 70)\n",
      "(2809, 70, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec5fe7e3",
   "metadata": {},
   "source": [
    "# 4. 모델 구축 및 학습\n",
    "## 모델 구성\n",
    "### 1. 입력을 실수 벡터로 임베딩\n",
    "### 2. 양뱡향 LSTM 구성\n",
    "### 3. Dense layer를 통한 각 태그에 속할 확률 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ebed667",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.9.0'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "eedf137e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, Bidirectional, TimeDistributed\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e188d334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 70, 128)           512000    \n",
      "                                                                 \n",
      " bidirectional (Bidirectiona  (None, 70, 512)          788480    \n",
      " l)                                                              \n",
      "                                                                 \n",
      " time_distributed (TimeDistr  (None, 70, 10)           5130      \n",
      " ibuted)                                                         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,305,610\n",
      "Trainable params: 1,305,610\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=vocab_size, output_dim=128, input_length=max_len, mask_zero=True))\n",
    "model.add(Bidirectional(LSTM(256, return_sequences=True)))\n",
    "model.add(TimeDistributed(Dense(tag_size, activation='softmax')))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a8f1444",
   "metadata": {},
   "source": [
    "## 4.2 모델 컴파일 및 학습 진행, 평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7f96aa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 15:11:43.306129: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2023-06-16 15:11:45.755433: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-06-16 15:11:46.394444: W tensorflow/core/common_runtime/forward_type_inference.cc:231] Type inference failed. This indicates an invalid graph that escaped type checking. Error message: INVALID_ARGUMENT: expected compatible input types, but input 1:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_LEGACY_VARIANT\n",
      "    }\n",
      "  }\n",
      "}\n",
      " is neither a subtype nor a supertype of the combined inputs preceding it:\n",
      "type_id: TFT_OPTIONAL\n",
      "args {\n",
      "  type_id: TFT_PRODUCT\n",
      "  args {\n",
      "    type_id: TFT_TENSOR\n",
      "    args {\n",
      "      type_id: TFT_FLOAT\n",
      "    }\n",
      "  }\n",
      "}\n",
      "\n",
      "\twhile inferring type of node 'cond_42/output/_19'\n",
      "2023-06-16 15:11:46.397395: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-06-16 15:11:46.524800: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-06-16 15:11:49.260976: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-06-16 15:11:49.370431: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - ETA: 0s - loss: 0.1886 - accuracy: 0.8232"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-16 15:12:24.290945: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-06-16 15:12:24.566634: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2023-06-16 15:12:24.608865: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 46s 441ms/step - loss: 0.1886 - accuracy: 0.8232 - val_loss: 0.1329 - val_accuracy: 0.8320\n",
      "Epoch 2/3\n",
      "88/88 [==============================] - 36s 415ms/step - loss: 0.1012 - accuracy: 0.8515 - val_loss: 0.0803 - val_accuracy: 0.8800\n",
      "Epoch 3/3\n",
      "88/88 [==============================] - 37s 415ms/step - loss: 0.0673 - accuracy: 0.9012 - val_loss: 0.0564 - val_accuracy: 0.9199\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x298267250>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=Adam(0.001),\n",
    "              metrics=['accuracy']\n",
    "             )\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=128, epochs=3, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fdbf4ccc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88/88 [==============================] - 6s 64ms/step - loss: 0.0564 - accuracy: 0.9199\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.05639009177684784, 0.9198888540267944]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8035c7",
   "metadata": {},
   "source": [
    "# 5. 학습한 모델을 통한 예측\n",
    "## 예측을 확인하기 위해서 인덱스를 단어로 변환해줄 사전이 필요\n",
    "## 사전은 토큰화 툴의 사전을 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "359e03e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2word = src_tokenizer.index_word\n",
    "idx2ner = tar_tokenizer.index_word\n",
    "idx2ner[0] = 'PAD'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cf825eee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 57ms/step\n",
      "단어              | 실제값   | 예측값\n",
      "----------------------------------\n",
      "feyenoord         | B-ORG   |B-ORG\n",
      "midfielder        | O       |O\n",
      "OOV               | B-PER   |B-PER\n",
      "van               | I-PER   |B-PER\n",
      "OOV               | I-PER   |I-PER\n",
      "was               | O       |O\n",
      "also              | O       |O\n",
      "named             | O       |O\n",
      "to                | O       |O\n",
      "make              | O       |O\n",
      "his               | O       |O\n",
      "debut             | O       |O\n",
      "in                | O       |O\n",
      "the               | O       |O\n",
      "OOV               | O       |O\n",
      "squad             | O       |O\n",
      ".                 | O       |O\n"
     ]
    }
   ],
   "source": [
    "i = 60\n",
    "y_predicted = model.predict(np.array([X_test[i]]))\n",
    "y_predicted = np.argmax(y_predicted, axis=-1)\n",
    "\n",
    "true = np.argmax(y_test[i], -1)\n",
    "\n",
    "print(\"{:15} | {:5} | {}\".format(\"단어\",\"실제값\",\"예측값\"))\n",
    "print(\"-\" * 34)\n",
    "\n",
    "for w, t, pred in zip(X_test[i], true, y_predicted[0]):\n",
    "    if w != 0:\n",
    "        print(\"{:17} | {:7} |{}\".format(idx2word[w], idx2ner[t].upper(), idx2ner[pred].upper()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898848bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47968f69",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "tf38_cpu",
   "language": "python",
   "name": "tf38_cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
